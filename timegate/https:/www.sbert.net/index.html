

<!doctype html>
    <html lang="en-US" id="template-archives" class="base">
        <head>
        
        <script defer data-domain="context.center" src="https://plausible.io/js/plausible.js"></script>
        <link rel="alternate" type="application/rss+xml" title="Context Center RSS" href="https://context.center/rss/" />
    	<link rel="alternate" type="application/atom+xml" title="Context Center Feed" href="https://context.center/feed/" />
        <meta charset="utf-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>SentenceTransformers Documentation — Sentence-Transformers  documentation</title>
        <link rel="original" http-equiv href="https://www.sbert.net/" />
        
            
                <!-- <link rel="stylesheet" href="https://context.center/assets/css/template-archives.css?v=2111521152" /> -->
                <link rel="stylesheet" href="https://context.center/assets/css/template-archives.css?v=2111521152" id=""></link>

            
        
        
            <link rel="canonical" href="https://www.sbert.net/" />
            

            <meta property="og:title"
                content="SentenceTransformers Documentation — Sentence-Transformers documentation">

            <meta property="og:description"
                content="You can install it using pip:">


            <meta property="og:url"
                content="https://www.sbert.net/" />

            <meta property="og:site_name" content="Context Center" />

            <meta property="og:locale" content="en_US" />

            <meta name="twitter:site" content="@chronotope" />

            <meta name="twitter:description" content="You can install it using pip:" />

            <!-- I prefer the summary_large_image Twitter card for posts. -->
            <meta name="twitter:card" content="summary_large_image" />
            <!-- You, you're the creator. -->
            <meta name="twitter:creator" content="@chronotope" />
            <!-- This property is for the article title, not site title. -->
            <meta name="twitter:title" content="SentenceTransformers Documentation — Sentence-Transformers documentation" />

            

            <meta property="og:type" content="website" />

            <script type="application/ld+json">
                {
                    "@context": "http://schema.org",
                    "@type": "WebPage",
                    "url": "https://www.sbert.net/",
                    "headline": "SentenceTransformers Documentation — Sentence-Transformers  documentation",
                    "about": "You can install it using pip:",

                    "image": [
                        
                        
                    ],
                    "isAccessibleForFree": "True",
                    "isPartOf": {
                        "@type": ["CreativeWork", "Product"],
                        "name": "Fight With Tools",
                        "productID": "fightwithtools.dev"
                    },
                    "license": "http://creativecommons.org/licenses/by-sa/4.0/",
                    "archivedAt": "https://context.center/timegate/https:/www.sbert.net/",
                    "sameAs": "https://www.sbert.net/",
                }
            </script>


        
        
        </head>
        <body >
            <div class="wrapper">
                <header>
                    <div class="left">
                        <h1>Archived: SentenceTransformers Documentation — Sentence-Transformers  documentation</h1>
                        <p>This is a simplified archive of the page at <a href="https://www.sbert.net/" target="_blank">https://www.sbert.net/</a></p>
                    </div>

                            <div id="share-embed">
                                <span>Use this page embed on your own site:</span>
                                <textarea id="html-embed" name="story" rows="8" cols="40">
                                    <script>window.contexterSetup=window.contexterSetup||function(){window.contexterSetupComplete=!0;class ContexterLink extends HTMLAnchorElement{constructor(){super()}connectedCallback(){this.setAttribute("target","_blank")}}customElements.define("contexter-link",ContexterLink,{extends:"a"}),customElements.define("contexter-inner",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className="contexter-box__inner"}}),customElements.define("contexter-thumbnail",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className="contexter-box__thumbnail"}}),customElements.define("contexter-byline",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className="contexter-box__byline"}}),customElements.define("contexter-keywordset",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className="contexter-box__keywordset"}}),customElements.define("contexter-linkset",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className="contexter-box__linkset"}}),customElements.define("contexter-meta",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className="contexter-box__meta"}}),customElements.define("contexter-summary",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className="p-summary entry-summary"}}),customElements.define("contexter-box-head",class extends HTMLElement{constructor(){super()}connectedCallback(){this.className="contexter-box__head"}}),customElements.define("contexter-box-inner",class extends HTMLElement{constructor(){super()}connectedCallback(){}});class ContexterBox extends HTMLElement{constructor(){super(),this.first=!0,this.shadow=this.attachShadow({mode:"open"})}connectedCallback(){if(this.first){this.first=!1;var style=document.createElement("style"),lightDomStyle=(style.innerHTML=`:host {--background: #f5f6f7;--border: darkblue;--blue: #0000ee;--font-color: black;--inner-border: black;font-family: Franklin,Arial,Helvetica,sans-serif;font-size: 14px;background: var(--background);width: 600px;color: var(--font-color);min-height: 90px;display: block;padding: 8px;border: 1px solid var(--border);cursor: pointer;box-sizing: border-box;margin: 6px;contain: content;margin: 6px auto;}// can only select top-level nodes with slotted::slotted(*) {max-width: 100%;display:block;}::slotted([slot=thumbnail]) {max-width: 100%;display:block;}::slotted([slot=header]) {width: 100%;font-size: 1.25rem;font-weight: bold;display:block;margin-bottom: 6px;}::slotted([slot=author]) {max-width: 50%;font-size: 12px;display:inline-block;float: left;}::slotted([slot=time]) {max-width: 50%;font-size: 12px;display:inline-block;float: right;}::slotted([slot=summary]) {width: 100%;margin-top: 6px;padding: 10px 2px;border-top: 1px solid var(--inner-border);font-size: 15px;display:inline-block;margin-bottom: 6px;}contexter-meta {height: auto;margin-bottom: 4px;width: 100%;display: grid;position: relative;min-height: 16px;grid-template-columns: repeat(2, 1fr);}::slotted([slot=keywords]) {width: 80%;padding: 2px 4px;border-top: 1px solid var(--inner-border);font-size: 11px;display: block;float: right;font-style: italic;text-align: right;grid-column: 2/2;grid-row: 1;align-self: end;justify-self: end;}::slotted([slot=keywords]):empty {border-top: 0px solid var(--inner-border);}::slotted([slot=archive-link]) {font-size: 1em;display: inline;}::slotted([slot=archive-link])::after {content: "|";display: inline;color: var(--font-color);text-decoration: none;margin: 0 .5em;}::slotted([slot=read-link]) {font-size: 1em;display: inline;}contexter-linkset {width: 80%;padding: 2px 4px;font-size: 13px;float: left;font-weight: bold;grid-row: 1;grid-column: 1/2;align-self: end;justify-self: start;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {:host {width: 310px;}}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){:host {--background: #354150;--border: #1f2b37;--blue: #55b0ff;--font-color: #ffffff;--inner-border: #787a7c;background: var(--background);border: 1px solid var(--border)}}`,document.createElement("style"));lightDomStyle.innerHTML=`contexter-box {contain: content;}contexter-box .read-link {font-weight: bold;}contexter-box a {color: #0000ee;}contexter-box img {width: 100%;border: 0;padding: 0;margin: 0;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {...}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){contexter-box a {color: #55b0ff;}}`,this.appendChild(lightDomStyle),this.shadow.appendChild(style);const innerContainer=document.createElement("contexter-box-inner"),innerSlotThumbnail=(this.shadow.appendChild(innerContainer),document.createElement("slot")),innerSlotHeader=(innerSlotThumbnail.name="thumbnail",innerContainer.appendChild(innerSlotThumbnail),document.createElement("slot")),innerSlotAuthor=(innerSlotHeader.name="header",innerContainer.appendChild(innerSlotHeader),document.createElement("slot")),innerSlotTime=(innerSlotAuthor.name="author",innerContainer.appendChild(innerSlotAuthor),document.createElement("slot")),innerSlotSummary=(innerSlotTime.name="time",innerContainer.appendChild(innerSlotTime),document.createElement("slot")),metaContainer=(innerSlotSummary.name="summary",innerContainer.appendChild(innerSlotSummary),document.createElement("contexter-meta")),innerSlotInfo=(innerContainer.appendChild(metaContainer),document.createElement("slot")),linkContainer=(innerSlotInfo.name="keywords",metaContainer.appendChild(innerSlotInfo),document.createElement("contexter-linkset")),innerSlotArchiveLink=(metaContainer.appendChild(linkContainer),document.createElement("slot")),innerSlotReadLink=(innerSlotArchiveLink.name="archive-link",linkContainer.appendChild(innerSlotArchiveLink),document.createElement("slot"));innerSlotReadLink.name="read-link",linkContainer.appendChild(innerSlotReadLink),this.className="contexter-box",this.onclick=e=>{if(!e.target.className.includes("read-link")&&!e.target.className.includes("title-link")){const mainLinks=this.querySelectorAll("a.main-link");mainLinks[0].click()}}}}}customElements.define("contexter-box",ContexterBox)},window.contexterSetupComplete||window.contexterSetup();</script><contexter-box class="link-card h-entry hentry" itemscope="" itemtype="https://schema.org/CreativeWork"><contexter-thumbnail class="thumbnail" slot="thumbnail"></contexter-thumbnail><contexter-box-head slot="header" class="p-name entry-title" itemprop="headline"><contexter-box-head slot="header" class="p-name entry-title" itemprop="headline"><a is="contexter-link" href="https://www.sbert.netindex.html/" itemprop="url">SentenceTransformers Documentation — Sentence-Transformers  documentation</a></contexter-box-head></contexter-box-head><time class="dt-published published" slot="time" itemprop="datePublished" datetime="2022-03-23T21:52:33.658Z">2/23/2022</time><contexter-summary class="p-summary entry-summary" itemprop="abstract" slot="summary"><p>You can install it using pip:</p></contexter-summary><contexter-keywordset itemprop="keywords" slot="keywords"></contexter-keywordset><a href="https://web.archive.org/web/20220323215237/https://www.sbert.net/" is="contexter-link" target="_blank" rel="timemap" class="read-link archive-link" itemprop="archivedAt" slot="archive-link">Archived</a><a is="contexter-link" href="https://www.sbert.netindex.html/" class="read-link main-link" itemprop="sameAs" slot="read-link">Read</a></contexter-box>
                                </textarea><br />
                                <button onclick="(function(e){ navigator.clipboard.writeText(document.getElementById('html-embed').value); })()">Copy</button>
                            </div>
                            
                            <script>window.contexterSetup=window.contexterSetup||function(){window.contexterSetupComplete=!0;class ContexterLink extends HTMLAnchorElement{constructor(){super()}connectedCallback(){this.setAttribute("target","_blank")}}customElements.define("contexter-link",ContexterLink,{extends:"a"}),customElements.define("contexter-inner",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className="contexter-box__inner"}}),customElements.define("contexter-thumbnail",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className="contexter-box__thumbnail"}}),customElements.define("contexter-byline",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className="contexter-box__byline"}}),customElements.define("contexter-keywordset",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className="contexter-box__keywordset"}}),customElements.define("contexter-linkset",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className="contexter-box__linkset"}}),customElements.define("contexter-meta",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className="contexter-box__meta"}}),customElements.define("contexter-summary",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className="p-summary entry-summary"}}),customElements.define("contexter-box-head",class extends HTMLElement{constructor(){super()}connectedCallback(){this.className="contexter-box__head"}}),customElements.define("contexter-box-inner",class extends HTMLElement{constructor(){super()}connectedCallback(){}});class ContexterBox extends HTMLElement{constructor(){super(),this.first=!0,this.shadow=this.attachShadow({mode:"open"})}connectedCallback(){if(this.first){this.first=!1;var style=document.createElement("style"),lightDomStyle=(style.innerHTML=`:host {--background: #f5f6f7;--border: darkblue;--blue: #0000ee;--font-color: black;--inner-border: black;font-family: Franklin,Arial,Helvetica,sans-serif;font-size: 14px;background: var(--background);width: 600px;color: var(--font-color);min-height: 90px;display: block;padding: 8px;border: 1px solid var(--border);cursor: pointer;box-sizing: border-box;margin: 6px;contain: content;margin: 6px auto;}// can only select top-level nodes with slotted::slotted(*) {max-width: 100%;display:block;}::slotted([slot=thumbnail]) {max-width: 100%;display:block;}::slotted([slot=header]) {width: 100%;font-size: 1.25rem;font-weight: bold;display:block;margin-bottom: 6px;}::slotted([slot=author]) {max-width: 50%;font-size: 12px;display:inline-block;float: left;}::slotted([slot=time]) {max-width: 50%;font-size: 12px;display:inline-block;float: right;}::slotted([slot=summary]) {width: 100%;margin-top: 6px;padding: 10px 2px;border-top: 1px solid var(--inner-border);font-size: 15px;display:inline-block;margin-bottom: 6px;}contexter-meta {height: auto;margin-bottom: 4px;width: 100%;display: grid;position: relative;min-height: 16px;grid-template-columns: repeat(2, 1fr);}::slotted([slot=keywords]) {width: 80%;padding: 2px 4px;border-top: 1px solid var(--inner-border);font-size: 11px;display: block;float: right;font-style: italic;text-align: right;grid-column: 2/2;grid-row: 1;align-self: end;justify-self: end;}::slotted([slot=keywords]):empty {border-top: 0px solid var(--inner-border);}::slotted([slot=archive-link]) {font-size: 1em;display: inline;}::slotted([slot=archive-link])::after {content: "|";display: inline;color: var(--font-color);text-decoration: none;margin: 0 .5em;}::slotted([slot=read-link]) {font-size: 1em;display: inline;}contexter-linkset {width: 80%;padding: 2px 4px;font-size: 13px;float: left;font-weight: bold;grid-row: 1;grid-column: 1/2;align-self: end;justify-self: start;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {:host {width: 310px;}}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){:host {--background: #354150;--border: #1f2b37;--blue: #55b0ff;--font-color: #ffffff;--inner-border: #787a7c;background: var(--background);border: 1px solid var(--border)}}`,document.createElement("style"));lightDomStyle.innerHTML=`contexter-box {contain: content;}contexter-box .read-link {font-weight: bold;}contexter-box a {color: #0000ee;}contexter-box img {width: 100%;border: 0;padding: 0;margin: 0;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {...}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){contexter-box a {color: #55b0ff;}}`,this.appendChild(lightDomStyle),this.shadow.appendChild(style);const innerContainer=document.createElement("contexter-box-inner"),innerSlotThumbnail=(this.shadow.appendChild(innerContainer),document.createElement("slot")),innerSlotHeader=(innerSlotThumbnail.name="thumbnail",innerContainer.appendChild(innerSlotThumbnail),document.createElement("slot")),innerSlotAuthor=(innerSlotHeader.name="header",innerContainer.appendChild(innerSlotHeader),document.createElement("slot")),innerSlotTime=(innerSlotAuthor.name="author",innerContainer.appendChild(innerSlotAuthor),document.createElement("slot")),innerSlotSummary=(innerSlotTime.name="time",innerContainer.appendChild(innerSlotTime),document.createElement("slot")),metaContainer=(innerSlotSummary.name="summary",innerContainer.appendChild(innerSlotSummary),document.createElement("contexter-meta")),innerSlotInfo=(innerContainer.appendChild(metaContainer),document.createElement("slot")),linkContainer=(innerSlotInfo.name="keywords",metaContainer.appendChild(innerSlotInfo),document.createElement("contexter-linkset")),innerSlotArchiveLink=(metaContainer.appendChild(linkContainer),document.createElement("slot")),innerSlotReadLink=(innerSlotArchiveLink.name="archive-link",linkContainer.appendChild(innerSlotArchiveLink),document.createElement("slot"));innerSlotReadLink.name="read-link",linkContainer.appendChild(innerSlotReadLink),this.className="contexter-box",this.onclick=e=>{if(!e.target.className.includes("read-link")&&!e.target.className.includes("title-link")){const mainLinks=this.querySelectorAll("a.main-link");mainLinks[0].click()}}}}}customElements.define("contexter-box",ContexterBox)},window.contexterSetupComplete||window.contexterSetup();</script><contexter-box class="link-card h-entry hentry" itemscope="" itemtype="https://schema.org/CreativeWork"><contexter-thumbnail class="thumbnail" slot="thumbnail"></contexter-thumbnail><contexter-box-head slot="header" class="p-name entry-title" itemprop="headline"><contexter-box-head slot="header" class="p-name entry-title" itemprop="headline"><a is="contexter-link" href="https://www.sbert.netindex.html/" itemprop="url">SentenceTransformers Documentation — Sentence-Transformers  documentation</a></contexter-box-head></contexter-box-head><time class="dt-published published" slot="time" itemprop="datePublished" datetime="2022-03-23T21:52:33.658Z">2/23/2022</time><contexter-summary class="p-summary entry-summary" itemprop="abstract" slot="summary"><p>You can install it using pip:</p></contexter-summary><contexter-keywordset itemprop="keywords" slot="keywords"></contexter-keywordset><a href="https://web.archive.org/web/20220323215237/https://www.sbert.net/" is="contexter-link" target="_blank" rel="timemap" class="read-link archive-link" itemprop="archivedAt" slot="archive-link">Archived</a><a is="contexter-link" href="https://www.sbert.netindex.html/" class="read-link main-link" itemprop="sameAs" slot="read-link">Read</a></contexter-box>
                            


                </header>
                <main>
                
                    <div id="readability-page-1" class="page"><div>
    
    <nav data-toggle="wy-nav-shift">
      
    </nav>

    <section data-toggle="wy-nav-shift">

      
      <nav aria-label="top navigation">
        
          <i data-toggle="wy-nav-top"></i>
          <a href="#">Sentence-Transformers</a>
        
      </nav>


      <div itemprop="articleBody" role="main" itemscope="itemscope" itemtype="http://schema.org/Article">
            
  
<div id="installation">
<h2>Installation<a href="#installation" title="Permalink to this headline">¶</a></h2>
<p>You can install it using pip:</p>
<div><pre><span></span><span>pip</span> <span>install</span> <span>-</span><span>U</span> <span>sentence</span><span>-</span><span>transformers</span>
</pre></div>
<p>We recommend <strong>Python 3.6</strong> or higher, and at least <strong>PyTorch 1.6.0</strong>. See <a href="docs/installation.html">installation</a> for further installation options, especially if you want to use a GPU.</p>
</div>
<div id="usage">
<h2>Usage<a href="#usage" title="Permalink to this headline">¶</a></h2>
<p>The usage is as simple as:</p>
<div><pre><span></span><span>from</span> <span>sentence_transformers</span> <span>import</span> <span>SentenceTransformer</span>
<span>model</span> <span>=</span> <span>SentenceTransformer</span><span>(</span><span>'paraphrase-MiniLM-L6-v2'</span><span>)</span>

<span>#Our sentences we like to encode</span>
<span>sentences</span> <span>=</span> <span>[</span><span>'This framework generates embeddings for each input sentence'</span><span>,</span>
    <span>'Sentences are passed as a list of string.'</span><span>,</span>
    <span>'The quick brown fox jumps over the lazy dog.'</span><span>]</span>

<span>#Sentences are encoded by calling model.encode()</span>
<span>embeddings</span> <span>=</span> <span>model</span><span>.</span><span>encode</span><span>(</span><span>sentences</span><span>)</span>

<span>#Print the embeddings</span>
<span>for</span> <span>sentence</span><span>,</span> <span>embedding</span> <span>in</span> <span>zip</span><span>(</span><span>sentences</span><span>,</span> <span>embeddings</span><span>):</span>
    <span>print</span><span>(</span><span>"Sentence:"</span><span>,</span> <span>sentence</span><span>)</span>
    <span>print</span><span>(</span><span>"Embedding:"</span><span>,</span> <span>embedding</span><span>)</span>
    <span>print</span><span>(</span><span>""</span><span>)</span>
</pre></div>
</div>
<div id="performance">
<h2>Performance<a href="#performance" title="Permalink to this headline">¶</a></h2>
<p>Our models are evaluated extensively and achieve state-of-the-art performance on various tasks. Further, the code is tuned to provide the highest possible speed. Have a look at <a href="https://www.sbert.net/docs/pretrained_models.html#sentence-embedding-models/">Pre-Trained Models</a> for an overview of available models and the respective performance on different tasks.</p>
</div>

<div id="citing-authors">
<h2>Citing &amp; Authors<a href="#citing-authors" title="Permalink to this headline">¶</a></h2>
<p>If you find this repository helpful, feel free to cite our publication <a href="https://arxiv.org/abs/1908.10084">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks</a>:</p>
<blockquote>
<div><pre><span></span><span>@inproceedings</span><span>{</span><span>reimers-2019-sentence-bert</span><span>,</span>
  <span>title</span> <span>=</span> <span>"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"</span><span>,</span>
  <span>author</span> <span>=</span> <span>"Reimers, Nils and Gurevych, Iryna"</span><span>,</span>
  <span>booktitle</span> <span>=</span> <span>"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing"</span><span>,</span>
  <span>month</span> <span>=</span> <span>"11"</span><span>,</span>
  <span>year</span> <span>=</span> <span>"2019"</span><span>,</span>
  <span>publisher</span> <span>=</span> <span>"Association for Computational Linguistics"</span><span>,</span>
  <span>url</span> <span>=</span> <span>"https://arxiv.org/abs/1908.10084"</span><span>,</span>
<span>}</span>
</pre></div></blockquote>
<p>If you use one of the multilingual models, feel free to cite our publication <a href="https://arxiv.org/abs/2004.09813">Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation</a>:</p>
<blockquote>
<div><pre><span></span><span>@inproceedings</span><span>{</span><span>reimers-2020-multilingual-sentence-bert</span><span>,</span>
  <span>title</span> <span>=</span> <span>"Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation"</span><span>,</span>
  <span>author</span> <span>=</span> <span>"Reimers, Nils and Gurevych, Iryna"</span><span>,</span>
  <span>booktitle</span> <span>=</span> <span>"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing"</span><span>,</span>
  <span>month</span> <span>=</span> <span>"11"</span><span>,</span>
  <span>year</span> <span>=</span> <span>"2020"</span><span>,</span>
  <span>publisher</span> <span>=</span> <span>"Association for Computational Linguistics"</span><span>,</span>
  <span>url</span> <span>=</span> <span>"https://arxiv.org/abs/2004.09813"</span><span>,</span>
<span>}</span>
</pre></div></blockquote>
<p>If you use the code for <a href="https://github.com/UKPLab/sentence-transformers/tree/master/examples/training/data_augmentation">data augmentation</a>, feel free to cite our publication <a href="https://arxiv.org/abs/2010.08240">Augmented SBERT: Data Augmentation Method for Improving Bi-Encoders for Pairwise Sentence Scoring Tasks</a>:</p>
<blockquote>
<div><pre><span></span><span>@inproceedings</span><span>{</span><span>thakur-2020-AugSBERT</span><span>,</span>
  <span>title</span> <span>=</span> <span>"Augmented {SBERT}: Data Augmentation Method for Improving Bi-Encoders for Pairwise Sentence Scoring Tasks"</span><span>,</span>
  <span>author</span> <span>=</span> <span>"Thakur, Nandan and Reimers, Nils and Daxenberger, Johannes  and Gurevych, Iryna"</span><span>,</span>
  <span>booktitle</span> <span>=</span> <span>"Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"</span><span>,</span>
  <span>month</span> <span>=</span> <span>jun</span><span>,</span>
  <span>year</span> <span>=</span> <span>"2021"</span><span>,</span>
  <span>address</span> <span>=</span> <span>"Online"</span><span>,</span>
  <span>publisher</span> <span>=</span> <span>"Association for Computational Linguistics"</span><span>,</span>
  <span>url</span> <span>=</span> <span>"https://www.aclweb.org/anthology/2021.naacl-main.28"</span><span>,</span>
  <span>pages</span> <span>=</span> <span>"296--310"</span><span>,</span>
<span>}</span>
</pre></div></blockquote>
<div>
<p><span>Overview</span></p>
<ul>
<li><a href="docs/installation.html">Installation</a><ul>
<li><a href="docs/installation.html#install-sentencetransformers">Install SentenceTransformers</a></li>
<li><a href="docs/installation.html#install-pytorch-with-cuda-support">Install PyTorch with CUDA-Support</a></li>
</ul>
</li>
<li><a href="docs/quickstart.html">Quickstart</a><ul>
<li><a href="docs/quickstart.html#comparing-sentence-similarities">Comparing Sentence Similarities</a></li>
<li><a href="docs/quickstart.html#pre-trained-models">Pre-Trained Models</a></li>
<li><a href="docs/quickstart.html#training-your-own-embeddings">Training your own Embeddings</a></li>
</ul>
</li>
<li><a href="docs/pretrained_models.html">Pretrained Models</a><ul>
<li><a href="docs/pretrained_models.html#model-overview">Model Overview</a></li>
<li><a href="docs/pretrained_models.html#semantic-search">Semantic Search</a></li>
<li><a href="docs/pretrained_models.html#multi-lingual-models">Multi-Lingual Models</a></li>
<li><a href="docs/pretrained_models.html#image-text-models">Image &amp; Text-Models</a></li>
<li><a href="docs/pretrained_models.html#other-models">Other Models</a></li>
</ul>
</li>
<li><a href="docs/pretrained_cross-encoders.html">Pretrained Cross-Encoders</a><ul>
<li><a href="docs/pretrained_cross-encoders.html#ms-marco">MS MARCO</a></li>
<li><a href="docs/pretrained_cross-encoders.html#squad-qnli">SQuAD (QNLI)</a></li>
<li><a href="docs/pretrained_cross-encoders.html#stsbenchmark">STSbenchmark</a></li>
<li><a href="docs/pretrained_cross-encoders.html#quora-duplicate-questions">Quora Duplicate Questions</a></li>
<li><a href="docs/pretrained_cross-encoders.html#nli">NLI</a></li>
</ul>
</li>
<li><a href="docs/publications.html">Publications</a></li>
</ul>
</div>
<div>
<p><span>Usage</span></p>
<ul>
<li><a href="examples/applications/computing-embeddings/README.html">Computing Sentence Embeddings</a><ul>
<li><a href="examples/applications/computing-embeddings/README.html#input-sequence-length">Input Sequence Length</a></li>
<li><a href="examples/applications/computing-embeddings/README.html#storing-loading-embeddings">Storing &amp; Loading Embeddings</a></li>
<li><a href="examples/applications/computing-embeddings/README.html#multi-process-multi-gpu-encoding">Multi-Process / Multi-GPU Encoding</a></li>
<li><a href="examples/applications/computing-embeddings/README.html#sentence-embeddings-with-transformers">Sentence Embeddings with Transformers</a></li>
</ul>
</li>
<li><a href="docs/usage/semantic_textual_similarity.html">Semantic Textual Similarity</a></li>
<li><a href="examples/applications/semantic-search/README.html">Semantic Search</a><ul>
<li><a href="examples/applications/semantic-search/README.html#background">Background</a></li>
<li><a href="examples/applications/semantic-search/README.html#symmetric-vs-asymmetric-semantic-search">Symmetric vs. Asymmetric Semantic Search</a></li>
<li><a href="examples/applications/semantic-search/README.html#python">Python</a></li>
<li><a href="examples/applications/semantic-search/README.html#util-semantic-search">util.semantic_search</a></li>
<li><a href="examples/applications/semantic-search/README.html#speed-optimization">Speed Optimization</a></li>
<li><a href="examples/applications/semantic-search/README.html#elasticsearch">ElasticSearch</a></li>
<li><a href="examples/applications/semantic-search/README.html#approximate-nearest-neighbor">Approximate Nearest Neighbor</a></li>
<li><a href="examples/applications/semantic-search/README.html#retrieve-re-rank">Retrieve &amp; Re-Rank</a></li>
<li><a href="examples/applications/semantic-search/README.html#examples">Examples</a></li>
</ul>
</li>
<li><a href="examples/applications/retrieve_rerank/README.html">Retrieve &amp; Re-Rank</a><ul>
<li><a href="examples/applications/retrieve_rerank/README.html#retrieve-re-rank-pipeline">Retrieve &amp; Re-Rank Pipeline</a></li>
<li><a href="examples/applications/retrieve_rerank/README.html#retrieval-bi-encoder">Retrieval: Bi-Encoder</a></li>
<li><a href="examples/applications/retrieve_rerank/README.html#re-ranker-cross-encoder">Re-Ranker: Cross-Encoder</a></li>
<li><a href="examples/applications/retrieve_rerank/README.html#example-scripts">Example Scripts</a></li>
<li><a href="examples/applications/retrieve_rerank/README.html#pre-trained-bi-encoders-retrieval">Pre-trained Bi-Encoders (Retrieval)</a></li>
<li><a href="examples/applications/retrieve_rerank/README.html#pre-trained-cross-encoders-re-ranker">Pre-trained Cross-Encoders (Re-Ranker)</a></li>
</ul>
</li>
<li><a href="examples/applications/clustering/README.html">Clustering</a><ul>
<li><a href="examples/applications/clustering/README.html#k-means">k-Means</a></li>
<li><a href="examples/applications/clustering/README.html#agglomerative-clustering">Agglomerative Clustering</a></li>
<li><a href="examples/applications/clustering/README.html#fast-clustering">Fast Clustering</a></li>
<li><a href="examples/applications/clustering/README.html#topic-modeling">Topic Modeling</a></li>
</ul>
</li>
<li><a href="examples/applications/paraphrase-mining/README.html">Paraphrase Mining</a></li>
<li><a href="examples/applications/parallel-sentence-mining/README.html">Translated Sentence Mining</a><ul>
<li><a href="examples/applications/parallel-sentence-mining/README.html#marging-based-mining">Marging Based Mining</a></li>
<li><a href="examples/applications/parallel-sentence-mining/README.html#examples">Examples</a></li>
</ul>
</li>
<li><a href="examples/applications/cross-encoder/README.html">Cross-Encoders</a><ul>
<li><a href="examples/applications/cross-encoder/README.html#bi-encoder-vs-cross-encoder">Bi-Encoder vs. Cross-Encoder</a></li>
<li><a href="examples/applications/cross-encoder/README.html#when-to-use-cross-bi-encoders">When to use Cross- / Bi-Encoders?</a></li>
<li><a href="examples/applications/cross-encoder/README.html#cross-encoders-usage">Cross-Encoders Usage</a></li>
<li><a href="examples/applications/cross-encoder/README.html#combining-bi-and-cross-encoders">Combining Bi- and Cross-Encoders</a></li>
<li><a href="examples/applications/cross-encoder/README.html#training-cross-encoders">Training Cross-Encoders</a></li>
</ul>
</li>
<li><a href="examples/applications/image-search/README.html">Image Search</a><ul>
<li><a href="examples/applications/image-search/README.html#installation">Installation</a></li>
<li><a href="examples/applications/image-search/README.html#usage">Usage</a></li>
<li><a href="examples/applications/image-search/README.html#examples">Examples</a></li>
</ul>
</li>
</ul>
</div>
<div>
<p><span>Training</span></p>
<ul>
<li><a href="docs/training/overview.html">Training Overview</a><ul>
<li><a href="docs/training/overview.html#network-architecture">Network Architecture</a></li>
<li><a href="docs/training/overview.html#creating-networks-from-scratch">Creating Networks from Scratch</a></li>
<li><a href="docs/training/overview.html#training-data">Training Data</a></li>
<li><a href="docs/training/overview.html#loss-functions">Loss Functions</a></li>
<li><a href="docs/training/overview.html#evaluators">Evaluators</a></li>
<li><a href="docs/training/overview.html#loading-custom-sentencetransformer-models">Loading Custom SentenceTransformer Models</a></li>
<li><a href="docs/training/overview.html#multitask-training">Multitask Training</a></li>
<li><a href="docs/training/overview.html#adding-special-tokens">Adding Special Tokens</a></li>
<li><a href="docs/training/overview.html#best-transformer-model">Best Transformer Model</a></li>
</ul>
</li>
<li><a href="examples/training/multilingual/README.html">Multilingual-Models</a><ul>
<li><a href="examples/training/multilingual/README.html#available-pre-trained-models">Available Pre-trained Models</a></li>
<li><a href="examples/training/multilingual/README.html#usage">Usage</a></li>
<li><a href="examples/training/multilingual/README.html#performance">Performance</a></li>
<li><a href="examples/training/multilingual/README.html#extend-your-own-models">Extend your own models</a></li>
<li><a href="examples/training/multilingual/README.html#training">Training</a></li>
<li><a href="examples/training/multilingual/README.html#data-format">Data Format</a></li>
<li><a href="examples/training/multilingual/README.html#loading-training-datasets">Loading Training Datasets</a></li>
<li><a href="examples/training/multilingual/README.html#sources-for-training-data">Sources for Training Data</a></li>
<li><a href="examples/training/multilingual/README.html#evaluation">Evaluation</a></li>
<li><a href="examples/training/multilingual/README.html#citation">Citation</a></li>
</ul>
</li>
<li><a href="examples/training/distillation/README.html">Model Distillation</a><ul>
<li><a href="examples/training/distillation/README.html#knowledge-distillation">Knowledge Distillation</a></li>
<li><a href="examples/training/distillation/README.html#speed-performance-trade-off">Speed - Performance Trade-Off</a></li>
<li><a href="examples/training/distillation/README.html#dimensionality-reduction">Dimensionality Reduction</a></li>
<li><a href="examples/training/distillation/README.html#quantization">Quantization</a></li>
</ul>
</li>
<li><a href="examples/training/cross-encoder/README.html">Cross-Encoders</a><ul>
<li><a href="examples/training/cross-encoder/README.html#examples">Examples</a></li>
<li><a href="examples/training/cross-encoder/README.html#training-crossencoders">Training CrossEncoders</a></li>
</ul>
</li>
<li><a href="examples/training/data_augmentation/README.html">Augmented SBERT</a><ul>
<li><a href="examples/training/data_augmentation/README.html#motivation">Motivation</a></li>
<li><a href="examples/training/data_augmentation/README.html#extend-to-your-own-datasets">Extend to your own datasets</a></li>
<li><a href="examples/training/data_augmentation/README.html#methodology">Methodology</a></li>
<li><a href="examples/training/data_augmentation/README.html#scenario-1-limited-or-small-annotated-datasets-few-labeled-sentence-pairs">Scenario 1: Limited or small annotated datasets (few labeled sentence-pairs)</a></li>
<li><a href="examples/training/data_augmentation/README.html#scenario-2-no-annotated-datasets-only-unlabeled-sentence-pairs">Scenario 2: No annotated datasets (Only unlabeled sentence-pairs)</a></li>
<li><a href="examples/training/data_augmentation/README.html#training">Training</a></li>
<li><a href="examples/training/data_augmentation/README.html#citation">Citation</a></li>
</ul>
</li>
</ul>
</div>
<div>
<p><span>Training Examples</span></p>
<ul>
<li><a href="examples/training/sts/README.html">Semantic Textual Similarity</a><ul>
<li><a href="examples/training/sts/README.html#training-data">Training data</a></li>
<li><a href="examples/training/sts/README.html#loss-function">Loss Function</a></li>
</ul>
</li>
<li><a href="examples/training/nli/README.html">Natural Language Inference</a><ul>
<li><a href="examples/training/nli/README.html#data">Data</a></li>
<li><a href="examples/training/nli/README.html#softmaxloss">SoftmaxLoss</a></li>
<li><a href="examples/training/nli/README.html#multiplenegativesrankingloss">MultipleNegativesRankingLoss</a></li>
</ul>
</li>
<li><a href="examples/training/paraphrases/README.html">Paraphrase Data</a><ul>
<li><a href="examples/training/paraphrases/README.html#datasets">Datasets</a></li>
<li><a href="examples/training/paraphrases/README.html#training">Training</a></li>
<li><a href="examples/training/paraphrases/README.html#pre-trained-models">Pre-Trained Models</a></li>
<li><a href="examples/training/paraphrases/README.html#work-in-progress">Work in Progress</a></li>
</ul>
</li>
<li><a href="examples/training/quora_duplicate_questions/README.html">Quora Duplicate Questions</a><ul>
<li><a href="examples/training/quora_duplicate_questions/README.html#pretrained-models">Pretrained Models</a></li>
<li><a href="examples/training/quora_duplicate_questions/README.html#dataset">Dataset</a></li>
<li><a href="examples/training/quora_duplicate_questions/README.html#usage">Usage</a></li>
<li><a href="examples/training/quora_duplicate_questions/README.html#training">Training</a></li>
<li><a href="examples/training/quora_duplicate_questions/README.html#multiplenegativesrankingloss">MultipleNegativesRankingLoss</a></li>
</ul>
</li>
<li><a href="examples/training/ms_marco/README.html">MS MARCO</a><ul>
<li><a href="examples/training/ms_marco/README.html#bi-encoder">Bi-Encoder</a></li>
<li><a href="examples/training/ms_marco/README.html#cross-encoder">Cross-Encoder</a></li>
<li><a href="examples/training/ms_marco/README.html#cross-encoder-knowledge-distillation">Cross-Encoder Knowledge Distillation</a></li>
</ul>
</li>
</ul>
</div>
<div>
<p><span>Unsupervised Learning</span></p>
<ul>
<li><a href="examples/unsupervised_learning/README.html">Unsupervised Learning</a><ul>
<li><a href="examples/unsupervised_learning/README.html#tsdae">TSDAE</a></li>
<li><a href="examples/unsupervised_learning/README.html#simcse">SimCSE</a></li>
<li><a href="examples/unsupervised_learning/README.html#ct">CT</a></li>
<li><a href="examples/unsupervised_learning/README.html#ct-in-batch-negative-sampling">CT (In-Batch Negative Sampling)</a></li>
<li><a href="examples/unsupervised_learning/README.html#masked-language-model-mlm">Masked Language Model (MLM)</a></li>
<li><a href="examples/unsupervised_learning/README.html#genq">GenQ</a></li>
<li><a href="examples/unsupervised_learning/README.html#gpl">GPL</a></li>
<li><a href="examples/unsupervised_learning/README.html#performance-comparison">Performance Comparison</a></li>
</ul>
</li>
<li><a href="examples/domain_adaptation/README.html">Domain Adaptation</a><ul>
<li><a href="examples/domain_adaptation/README.html#domain-adaptation-vs-unsupervised-learning">Domain Adaptation vs. Unsupervised Learning</a></li>
<li><a href="examples/domain_adaptation/README.html#adaptive-pre-training">Adaptive Pre-Training</a></li>
<li><a href="examples/domain_adaptation/README.html#gpl-generative-pseudo-labeling">GPL: Generative Pseudo-Labeling</a></li>
</ul>
</li>
</ul>
</div>

</div>


           </div>

    </section>

  </div></div>
                
                </main>
                <footer>

                </footer>
            </div>
            <!--[if !IE]><script>fixScale(document);</script><![endif]-->
        </body>
    </html>
